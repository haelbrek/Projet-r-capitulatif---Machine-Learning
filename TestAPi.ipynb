{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tracks.csv')\n",
    "df.release_date = pd.to_datetime(df.release_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000 = df[df.release_date > '2000']\n",
    "df_2000.drop(['id'],axis=1,inplace=True)\n",
    "df_2000.drop_duplicates(inplace=True)\n",
    "df_2000['Year'] = pd.to_datetime(df_2000.release_date).dt.year\n",
    "df_2000['month'] = pd.to_datetime(df_2000.release_date).dt.month\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split,learning_curve,cross_val_predict,cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet,SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from catboost import CatBoostRegressor\n",
    "R_algorithm = [LinearRegression(),ElasticNet(),SGDRegressor(),XGBRegressor(),SVR(),BayesianRidge(),KernelRidge(),CatBoostRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 166972 entries, 264091 to 200305\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   duration_ms       166972 non-null  int64  \n",
      " 1   explicit          166972 non-null  int64  \n",
      " 2   danceability      166972 non-null  float64\n",
      " 3   energy            166972 non-null  float64\n",
      " 4   key               166972 non-null  int64  \n",
      " 5   loudness          166972 non-null  float64\n",
      " 6   mode              166972 non-null  int64  \n",
      " 7   speechiness       166972 non-null  float64\n",
      " 8   acousticness      166972 non-null  float64\n",
      " 9   instrumentalness  166972 non-null  float64\n",
      " 10  liveness          166972 non-null  float64\n",
      " 11  valence           166972 non-null  float64\n",
      " 12  tempo             166972 non-null  float64\n",
      " 13  time_signature    166972 non-null  int64  \n",
      " 14  Year              166972 non-null  int64  \n",
      " 15  target            166972 non-null  int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 21.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 13.284096741596448\n"
     ]
    }
   ],
   "source": [
    "X = df_2000.drop(['popularity','name','artists','release_date','id_artists'], axis=1)\n",
    "y = df_2000['popularity']\n",
    "\n",
    "# Convert the list column to string column\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Preprocess the training data\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_transformer, num_cols),\n",
    "                                                ('cat', cat_transformer, cat_cols)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment_id = mlflow.create_experiment(\"Spotify_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "eval_data = X_train\n",
    "eval_data[\"target\"] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 3) Processing columntransformer, total=   0.1s\n",
      "[Pipeline]  (step 2 of 3) Processing polynomialfeatures, total=   0.2s\n",
      "[Pipeline] ........ (step 3 of 3) Processing elasticnet, total=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/02/21 15:52:16 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/02/21 15:52:18 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Permutation is used.\n",
      "Permutation explainer: 2001it [08:41,  3.80it/s]                          \n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n"
     ]
    }
   ],
   "source": [
    "for algorithm in R_algorithm :\n",
    "\n",
    "    pipe = make_pipeline(preprocessor,PolynomialFeatures(),algorithm)\n",
    "    pipe.fit(X_train,y_train)\n",
    "    print(\"l'algorithme {} est terminé, enregistrement dans mlflow \").__format__(str(algorithm))\n",
    "    with mlflow.start_run(experiment_id=experiment_id):\n",
    "\n",
    "        model_info = mlflow.sklearn.log_model(pipe, \"model\")\n",
    "        for k,v in pipe.named_steps[-1].get_params().items():\n",
    "            mlflow.log_param(k,v)\n",
    "        result = mlflow.evaluate(\n",
    "            model_info.model_uri,\n",
    "            eval_data,\n",
    "            targets=\"target\",\n",
    "            model_type=\"regressor\",\n",
    "            evaluators=[\"default\"],\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov  4 2022, 13:48:29) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37227ed9c485f36684c918ad2ebf286762189d6ce6ae0d84fce244b97886ca3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tracks.csv')\n",
    "df.release_date = pd.to_datetime(df.release_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000 = df[df.release_date > '2000']\n",
    "df_2000.drop(['id'], axis=1, inplace=True)\n",
    "df_2000.drop_duplicates(inplace=True)\n",
    "df_2000['Year'] = pd.to_datetime(df_2000.release_date).dt.year\n",
    "df_2000['month'] = pd.to_datetime(df_2000.release_date).dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, learning_curve, cross_val_predict, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from catboost import CatBoostRegressor\n",
    "R_algorithm = [LinearRegression(), ElasticNet(), SGDRegressor(\n",
    "), XGBRegressor(), SVR(), BayesianRidge(), KernelRidge(), CatBoostRegressor()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 13.284096741596448\n"
     ]
    }
   ],
   "source": [
    "X = df_2000.drop(['popularity', 'name', 'artists',\n",
    "                 'release_date', 'id_artists'], axis=1)\n",
    "y = df_2000['popularity']\n",
    "\n",
    "# Convert the list column to string column\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Preprocess the training data\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_transformer, num_cols),\n",
    "                                               ('cat', cat_transformer, cat_cols)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "from urllib.parse import urlparse\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment_id = mlflow.create_experiment(\"Spotify_prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "eval_data = X_train\n",
    "eval_data[\"target\"] = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 3) Processing columntransformer, total=   0.1s\n",
      "[Pipeline]  (step 2 of 3) Processing polynomialfeatures, total=   0.2s\n",
      "[Pipeline] ........ (step 3 of 3) Processing elasticnet, total=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/02/21 15:52:16 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/02/21 15:52:18 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Permutation is used.\n",
      "Permutation explainer: 2001it [08:41,  3.80it/s]                          \n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n"
     ]
    }
   ],
   "source": [
    "for algorithm in R_algorithm:\n",
    "\n",
    "    pipe = make_pipeline(preprocessor, PolynomialFeatures(), algorithm)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(\"l'algorithme {} est terminé, enregistrement dans mlflow \").__format__(\n",
    "        str(algorithm))\n",
    "    with mlflow.start_run(experiment_id=experiment_id):\n",
    "\n",
    "        model_info = mlflow.sklearn.log_model(pipe, \"model\")\n",
    "        for k, v in pipe.named_steps[-1].get_params().items():\n",
    "            mlflow.log_param(k, v)\n",
    "        result = mlflow.evaluate(\n",
    "            model_info.model_uri,\n",
    "            eval_data,\n",
    "            targets=\"target\",\n",
    "            model_type=\"regressor\",\n",
    "            evaluators=[\"default\"],\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#GENRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = pd.read_csv('data_110000k_lignes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_genre = genre.genre.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_genre(track_name):\n",
    "\n",
    "    base_url = 'http://ws.audioscrobbler.com/2.0/'\n",
    "    params = {'method': 'track.search',\n",
    "            'track': track_name,\n",
    "            'api_key': 'd30646344918494a4e45ea08ad6fc629',\n",
    "            'format': 'json'}\n",
    "\n",
    "    # Make the request to LastFM\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    # Check to make sure the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Get the tags from the response\n",
    "        data = response.json()\n",
    "        results = data['results']['trackmatches']['track']\n",
    "        try :\n",
    "            artist_name = results[0]['artist'] \n",
    "        except :\n",
    "            artist_name = 'None'\n",
    "    \n",
    "    base_url = 'http://ws.audioscrobbler.com/2.0/'\n",
    "    params = {'method': 'track.gettoptags',\n",
    "            'artist': artist_name,\n",
    "            'track': track_name,\n",
    "            'api_key': 'd30646344918494a4e45ea08ad6fc629',\n",
    "            'format': 'json'}\n",
    "\n",
    "    # Make the request to LastFM\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    # Check to make sure the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Get the tags from the response\n",
    "        tags = response.json().get('toptags', {}).get('tag', [])\n",
    "        genre = \n",
    "        # Print out the tags\n",
    "        for tag in tags:\n",
    "            var = tag.get('name')\n",
    "            if var in liste_genre:\n",
    "                genre = var\n",
    "                break\n",
    "            return genre\n",
    "    else :\n",
    "        return 'Others'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pop'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_genre('Thriller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('df_projet_recapitulatif_200.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates('track_id', inplace=True)\n",
    "df1.drop_duplicates(['track_duration', 'track_release_date', 'nombre_artist',\n",
    "                     'track_release_month', 'danceability', 'energy', 'key', 'loudness',\n",
    "                     'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "                     'valence', 'tempo', 'time_signature', 'pays_du_producteur',\n",
    "                     'popularity'], inplace=True)\n",
    "df1.drop(['track_id', 'album_type'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['genre']= 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df1\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m      2\u001b[0m     row\u001b[39m.\u001b[39mgenre\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:1409\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1407\u001b[0m klass \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_sliced\n\u001b[1;32m   1408\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues):\n\u001b[0;32m-> 1409\u001b[0m     s \u001b[39m=\u001b[39m klass(v, index\u001b[39m=\u001b[39;49mcolumns, name\u001b[39m=\u001b[39;49mk)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1410\u001b[0m     \u001b[39myield\u001b[39;00m k, s\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:470\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    468\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    469\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    472\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/construction.py:597\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    594\u001b[0m             subarr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m         \u001b[39m# we will try to copy by-definition here\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m         subarr \u001b[39m=\u001b[39m _try_cast(data, dtype, copy, raise_cast_failure)\n\u001b[1;32m    599\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ABCExtensionArray):\n\u001b[1;32m    600\u001b[0m     \u001b[39m# it is already ensured above this is not a PandasArray\u001b[39;00m\n\u001b[1;32m    601\u001b[0m     subarr \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/construction.py:777\u001b[0m, in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m    775\u001b[0m     \u001b[39mreturn\u001b[39;00m sanitize_to_nanoseconds(arr, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m--> 777\u001b[0m out \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(arr)\n\u001b[1;32m    778\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m arr \u001b[39mand\u001b[39;00m copy:\n\u001b[1;32m    779\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1243\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1241\u001b[0m         \u001b[39mreturn\u001b[39;00m td_values\u001b[39m.\u001b[39mreshape(shape)\n\u001b[0;32m-> 1243\u001b[0m inferred_type, seen_str \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49minfer_datetimelike_array(ensure_object(v))\n\u001b[1;32m   1244\u001b[0m \u001b[39mif\u001b[39;00m inferred_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mperiod\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minterval\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1245\u001b[0m     \u001b[39m# Incompatible return value type (got \"Union[ExtensionArray, ndarray]\",\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m     \u001b[39m# expected \"Union[ndarray, DatetimeArray, TimedeltaArray, PeriodArray,\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m     \u001b[39m# IntervalArray]\")\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmaybe_convert_objects(  \u001b[39m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m         v, convert_period\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, convert_interval\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in df1.iterrows():\n",
    "    row.genre=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "          ... \n",
       "230841    None\n",
       "230842    None\n",
       "230843    None\n",
       "230844    None\n",
       "230845    None\n",
       "Name: genre, Length: 225542, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None    225542\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.genre.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37227ed9c485f36684c918ad2ebf286762189d6ce6ae0d84fce244b97886ca3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
